{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================= Start of importing required packages and libraries =========================================#\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from experiment_federated import *\n",
    "import random\n",
    "#================================== End of importing required packages and libraries ==========================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "#=============================== Defining global variables ========================#\n",
    "DATASET_NAME = \"CIFAR10\"\n",
    "MODEL_NAME = \"ResNet18\"\n",
    "DD_TYPE = 'NON_IID'\n",
    "ALPHA = 1\n",
    "NUM_PEERS = 20 # \"number of peers: K\" \n",
    "FRAC_PEERS = 1 #'the fraction of peers: C to bel selected in each round'\n",
    "SEED = 7 #fixed seed\n",
    "random.seed(SEED)\n",
    "CRITERION = nn.CrossEntropyLoss()\n",
    "GLOBAL_ROUNDS = 100 #\"number of rounds of federated model training\"\n",
    "LOCAL_EPOCHS = 3 #\"the number of local epochs: E for each peer\"\n",
    "TEST_BATCH_SIZE = 1000\n",
    "LOCAL_BS = 32 #\"local batch size: B for each peer\"\n",
    "LOCAL_LR =  0.01#local learning rate: lr for each peer\n",
    "LOCAL_MOMENTUM = 0.9 #local momentum for each peer\n",
    "NUM_CLASSES = 10 # number of classes in an experiment\n",
    "LABELS_DICT = {'Plane':0,\n",
    "               'Car':1, \n",
    "               'Bird':2, \n",
    "               'Cat':3, \n",
    "               'Deer':4,\n",
    "               'Dog':5, \n",
    "               'Frog':6, \n",
    "               'Horse':7, \n",
    "               'Ship':8, \n",
    "               'Truck':9}\n",
    "\n",
    "#select the device to work with cpu or gpu\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    print('GPU is available:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print('GPU is not available, CPU will be used')\n",
    "DEVICE = torch.device(DEVICE)\n",
    "SOURCE_CLASS = 5 # the source class\n",
    "TARGET_CLASS = 3 # the target class \n",
    "\n",
    "CLASS_PER_PEER = 1\n",
    "SAMPLES_PER_CLASS = 582\n",
    "RATE_UNBALANCE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Starting experiment...\n",
      "--> Loading of CIFAR10 dataset\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "--> Dataset has been loaded!\n",
      "--> Creating ResNet18 model.....\n",
      "--> Model has been created!\n",
      "--> Distributing training data among peers\n",
      "--> Training data have been distributed among peers\n",
      "--> Creating peets instances\n",
      "Data set: CIFAR10\n",
      "Data distribution: NON_IID\n",
      "Aggregation rule: fedavg\n",
      "Attack Type: label_flipping\n",
      "Attackers Ratio: 0 %\n",
      "Malicious Behavior Rate: 100 %\n",
      "\n",
      "===>Simulation started...\n",
      "\n",
      "====>Global model training started...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828c1e6974774833a749530e806628e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global training round : 1/100 |\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m MALICIOUS_BEHAVIOR_RATE \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m atr \u001b[39min\u001b[39;00m [\u001b[39m0\u001b[39m, \u001b[39m0.4\u001b[39m]: \u001b[39m#attack success rate by default is 54.6\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     run_exp(dataset_name \u001b[39m=\u001b[39;49m DATASET_NAME, model_name \u001b[39m=\u001b[39;49m MODEL_NAME, dd_type \u001b[39m=\u001b[39;49m DD_TYPE, num_peers \u001b[39m=\u001b[39;49m NUM_PEERS, \n\u001b[0;32m      7\u001b[0m             frac_peers \u001b[39m=\u001b[39;49m FRAC_PEERS, seed \u001b[39m=\u001b[39;49m SEED, test_batch_size \u001b[39m=\u001b[39;49m TEST_BATCH_SIZE,\n\u001b[0;32m      8\u001b[0m                 criterion \u001b[39m=\u001b[39;49m CRITERION, global_rounds \u001b[39m=\u001b[39;49m GLOBAL_ROUNDS, local_epochs \u001b[39m=\u001b[39;49m LOCAL_EPOCHS, local_bs \u001b[39m=\u001b[39;49m LOCAL_BS, \n\u001b[0;32m      9\u001b[0m                  local_lr \u001b[39m=\u001b[39;49m LOCAL_LR, local_momentum \u001b[39m=\u001b[39;49m LOCAL_MOMENTUM, labels_dict \u001b[39m=\u001b[39;49m LABELS_DICT, device \u001b[39m=\u001b[39;49m DEVICE,\n\u001b[0;32m     10\u001b[0m                 attackers_ratio \u001b[39m=\u001b[39;49m atr, attack_type\u001b[39m=\u001b[39;49mATTACK_TYPE, \n\u001b[0;32m     11\u001b[0m                  malicious_behavior_rate \u001b[39m=\u001b[39;49m MALICIOUS_BEHAVIOR_RATE, rule \u001b[39m=\u001b[39;49m RULE,\n\u001b[0;32m     12\u001b[0m                 source_class \u001b[39m=\u001b[39;49m SOURCE_CLASS, target_class \u001b[39m=\u001b[39;49m TARGET_CLASS,\n\u001b[0;32m     13\u001b[0m                class_per_peer \u001b[39m=\u001b[39;49m CLASS_PER_PEER, samples_per_class \u001b[39m=\u001b[39;49m SAMPLES_PER_CLASS, \n\u001b[0;32m     14\u001b[0m                rate_unbalance \u001b[39m=\u001b[39;49m RATE_UNBALANCE, alpha \u001b[39m=\u001b[39;49m ALPHA, resume \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\edube\\Desktop\\MastersThesisCode\\experiment_federated.py:25\u001b[0m, in \u001b[0;36mrun_exp\u001b[1;34m(dataset_name, model_name, dd_type, num_peers, frac_peers, seed, test_batch_size, criterion, global_rounds, local_epochs, local_bs, local_lr, local_momentum, labels_dict, device, attackers_ratio, attack_type, malicious_behavior_rate, rule, class_per_peer, samples_per_class, rate_unbalance, alpha, source_class, target_class, resume)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMalicious Behavior Rate:\u001b[39m\u001b[39m'\u001b[39m, malicious_behavior_rate\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39m# flEnv.simulate(attack_type = attack_type, malicious_behavior_rate = malicious_behavior_rate,\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m#                 from_class = from_class, to_class = to_class,\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m#                  rule=rule)\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m flEnv\u001b[39m.\u001b[39;49mrun_experiment(attack_type \u001b[39m=\u001b[39;49m attack_type, malicious_behavior_rate \u001b[39m=\u001b[39;49m malicious_behavior_rate, \n\u001b[0;32m     26\u001b[0m                 source_class \u001b[39m=\u001b[39;49m source_class, target_class \u001b[39m=\u001b[39;49m target_class, \n\u001b[0;32m     27\u001b[0m                 rule\u001b[39m=\u001b[39;49mrule, resume \u001b[39m=\u001b[39;49m resume)\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m--> End of Experiment.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\edube\\Desktop\\MastersThesisCode\\environment_federated.py:323\u001b[0m, in \u001b[0;36mFL.run_experiment\u001b[1;34m(self, attack_type, malicious_behavior_rate, source_class, target_class, rule, resume)\u001b[0m\n\u001b[0;32m    320\u001b[0m peers_types\u001b[39m.\u001b[39mappend(mapping[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpeers[peer]\u001b[39m.\u001b[39mpeer_type])\n\u001b[0;32m    321\u001b[0m \u001b[39m# print(i)\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[39m# print('\\n{}: {} Starts training in global round:{} |'.format(i, (self.peers_pseudonyms[peer]), (epoch + 1)))\u001b[39;00m\n\u001b[1;32m--> 323\u001b[0m peer_update, peer_grad, peer_local_model, peer_loss, attacked, t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpeers[peer]\u001b[39m.\u001b[39;49mparticipant_update(epoch, \n\u001b[0;32m    324\u001b[0m copy\u001b[39m.\u001b[39;49mdeepcopy(simulation_model),\n\u001b[0;32m    325\u001b[0m attack_type \u001b[39m=\u001b[39;49m attack_type, malicious_behavior_rate \u001b[39m=\u001b[39;49m malicious_behavior_rate, \n\u001b[0;32m    326\u001b[0m source_class \u001b[39m=\u001b[39;49m source_class, target_class \u001b[39m=\u001b[39;49m target_class, dataset_name \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_name)\n\u001b[0;32m    328\u001b[0m local_weights\u001b[39m.\u001b[39mappend(peer_update)\n\u001b[0;32m    329\u001b[0m local_grads\u001b[39m.\u001b[39mappend(peer_grad)\n",
      "File \u001b[1;32mc:\\Users\\edube\\Desktop\\MastersThesisCode\\environment_federated.py:101\u001b[0m, in \u001b[0;36mPeer.participant_update\u001b[1;34m(self, global_epoch, model, attack_type, malicious_behavior_rate, source_class, target_class, dataset_name)\u001b[0m\n\u001b[0;32m     99\u001b[0m             peer_grad\u001b[39m.\u001b[39mappend(params\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mclone())\n\u001b[0;32m    100\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m             peer_grad[i]\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m params\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mclone()   \n\u001b[0;32m    102\u001b[0m t\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m cur_time    \n\u001b[0;32m    103\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Baseline|: FedAvg-no attacks (FL)\n",
    "RULE = 'fedavg'\n",
    "ATTACK_TYPE='label_flipping'\n",
    "MALICIOUS_BEHAVIOR_RATE = 1\n",
    "for atr in [0, 0.4]: #attack success rate by default is 54.6\n",
    "    run_exp(dataset_name = DATASET_NAME, model_name = MODEL_NAME, dd_type = DD_TYPE, num_peers = NUM_PEERS, \n",
    "            frac_peers = FRAC_PEERS, seed = SEED, test_batch_size = TEST_BATCH_SIZE,\n",
    "                criterion = CRITERION, global_rounds = GLOBAL_ROUNDS, local_epochs = LOCAL_EPOCHS, local_bs = LOCAL_BS, \n",
    "                 local_lr = LOCAL_LR, local_momentum = LOCAL_MOMENTUM, labels_dict = LABELS_DICT, device = DEVICE,\n",
    "                attackers_ratio = atr, attack_type=ATTACK_TYPE, \n",
    "                 malicious_behavior_rate = MALICIOUS_BEHAVIOR_RATE, rule = RULE,\n",
    "                source_class = SOURCE_CLASS, target_class = TARGET_CLASS,\n",
    "               class_per_peer = CLASS_PER_PEER, samples_per_class = SAMPLES_PER_CLASS, \n",
    "               rate_unbalance = RATE_UNBALANCE, alpha = ALPHA, resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'median'\n",
    "ATTACK_TYPE='label_flipping'\n",
    "MALICIOUS_BEHAVIOR_RATE = 1\n",
    "for atr in [0.4]:\n",
    "    run_exp(dataset_name = DATASET_NAME, model_name = MODEL_NAME, dd_type = DD_TYPE, num_peers = NUM_PEERS, \n",
    "            frac_peers = FRAC_PEERS, seed = SEED, test_batch_size = TEST_BATCH_SIZE,\n",
    "                criterion = CRITERION, global_rounds = GLOBAL_ROUNDS, local_epochs = LOCAL_EPOCHS, local_bs = LOCAL_BS, \n",
    "                 local_lr = LOCAL_LR, local_momentum = LOCAL_MOMENTUM, labels_dict = LABELS_DICT, device = DEVICE,\n",
    "                attackers_ratio = atr, attack_type=ATTACK_TYPE, \n",
    "                 malicious_behavior_rate = MALICIOUS_BEHAVIOR_RATE, rule = RULE,\n",
    "                source_class = SOURCE_CLASS, target_class = TARGET_CLASS,\n",
    "               class_per_peer = CLASS_PER_PEER, samples_per_class = SAMPLES_PER_CLASS, \n",
    "               rate_unbalance = RATE_UNBALANCE, alpha = ALPHA, resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'tmean'\n",
    "ATTACK_TYPE='label_flipping'\n",
    "MALICIOUS_BEHAVIOR_RATE = 1\n",
    "for atr in [0.4]:\n",
    "    run_exp(dataset_name = DATASET_NAME, model_name = MODEL_NAME, dd_type = DD_TYPE, num_peers = NUM_PEERS, \n",
    "            frac_peers = FRAC_PEERS, seed = SEED, test_batch_size = TEST_BATCH_SIZE,\n",
    "                criterion = CRITERION, global_rounds = GLOBAL_ROUNDS, local_epochs = LOCAL_EPOCHS, local_bs = LOCAL_BS, \n",
    "                 local_lr = LOCAL_LR, local_momentum = LOCAL_MOMENTUM, labels_dict = LABELS_DICT, device = DEVICE,\n",
    "                attackers_ratio = atr, attack_type=ATTACK_TYPE, \n",
    "                 malicious_behavior_rate = MALICIOUS_BEHAVIOR_RATE, rule = RULE,\n",
    "                source_class = SOURCE_CLASS, target_class = TARGET_CLASS,\n",
    "               class_per_peer = CLASS_PER_PEER, samples_per_class = SAMPLES_PER_CLASS, \n",
    "               rate_unbalance = RATE_UNBALANCE, alpha = ALPHA, resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'mkrum'\n",
    "ATTACK_TYPE='label_flipping'\n",
    "MALICIOUS_BEHAVIOR_RATE = 1\n",
    "for atr in [0.4]:\n",
    "    run_exp(dataset_name = DATASET_NAME, model_name = MODEL_NAME, dd_type = DD_TYPE, num_peers = NUM_PEERS, \n",
    "            frac_peers = FRAC_PEERS, seed = SEED, test_batch_size = TEST_BATCH_SIZE,\n",
    "                criterion = CRITERION, global_rounds = GLOBAL_ROUNDS, local_epochs = LOCAL_EPOCHS, local_bs = LOCAL_BS, \n",
    "                 local_lr = LOCAL_LR, local_momentum = LOCAL_MOMENTUM, labels_dict = LABELS_DICT, device = DEVICE,\n",
    "                attackers_ratio = atr, attack_type=ATTACK_TYPE, \n",
    "                 malicious_behavior_rate = MALICIOUS_BEHAVIOR_RATE, rule = RULE,\n",
    "                source_class = SOURCE_CLASS, target_class = TARGET_CLASS,\n",
    "               class_per_peer = CLASS_PER_PEER, samples_per_class = SAMPLES_PER_CLASS, \n",
    "               rate_unbalance = RATE_UNBALANCE, alpha = ALPHA, resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'foolsgold'\n",
    "ATTACK_TYPE='label_flipping'\n",
    "MALICIOUS_BEHAVIOR_RATE = 1\n",
    "for atr in [0.4]:\n",
    "    run_exp(dataset_name = DATASET_NAME, model_name = MODEL_NAME, dd_type = DD_TYPE, num_peers = NUM_PEERS, \n",
    "            frac_peers = FRAC_PEERS, seed = SEED, test_batch_size = TEST_BATCH_SIZE,\n",
    "                criterion = CRITERION, global_rounds = GLOBAL_ROUNDS, local_epochs = LOCAL_EPOCHS, local_bs = LOCAL_BS, \n",
    "                 local_lr = LOCAL_LR, local_momentum = LOCAL_MOMENTUM, labels_dict = LABELS_DICT, device = DEVICE,\n",
    "                attackers_ratio = atr, attack_type=ATTACK_TYPE, \n",
    "                 malicious_behavior_rate = MALICIOUS_BEHAVIOR_RATE, rule = RULE,\n",
    "                source_class = SOURCE_CLASS, target_class = TARGET_CLASS,\n",
    "               class_per_peer = CLASS_PER_PEER, samples_per_class = SAMPLES_PER_CLASS, \n",
    "               rate_unbalance = RATE_UNBALANCE, alpha = ALPHA, resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'Tolpegin'\n",
    "ATTACK_TYPE='label_flipping'\n",
    "MALICIOUS_BEHAVIOR_RATE = 1\n",
    "for atr in [0.4]:\n",
    "    run_exp(dataset_name = DATASET_NAME, model_name = MODEL_NAME, dd_type = DD_TYPE, num_peers = NUM_PEERS, \n",
    "            frac_peers = FRAC_PEERS, seed = SEED, test_batch_size = TEST_BATCH_SIZE,\n",
    "                criterion = CRITERION, global_rounds = GLOBAL_ROUNDS, local_epochs = LOCAL_EPOCHS, local_bs = LOCAL_BS, \n",
    "                 local_lr = LOCAL_LR, local_momentum = LOCAL_MOMENTUM, labels_dict = LABELS_DICT, device = DEVICE,\n",
    "                attackers_ratio = atr, attack_type=ATTACK_TYPE, \n",
    "                 malicious_behavior_rate = MALICIOUS_BEHAVIOR_RATE, rule = RULE,\n",
    "                source_class = SOURCE_CLASS, target_class = TARGET_CLASS,\n",
    "               class_per_peer = CLASS_PER_PEER, samples_per_class = SAMPLES_PER_CLASS, \n",
    "               rate_unbalance = RATE_UNBALANCE, alpha = ALPHA, resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'FLAME'\n",
    "ATTACK_TYPE='label_flipping'\n",
    "MALICIOUS_BEHAVIOR_RATE = 1\n",
    "for atr in [0.4]:\n",
    "    run_exp(dataset_name = DATASET_NAME, model_name = MODEL_NAME, dd_type = DD_TYPE, num_peers = NUM_PEERS, \n",
    "            frac_peers = FRAC_PEERS, seed = SEED, test_batch_size = TEST_BATCH_SIZE,\n",
    "                criterion = CRITERION, global_rounds = GLOBAL_ROUNDS, local_epochs = LOCAL_EPOCHS, local_bs = LOCAL_BS, \n",
    "                 local_lr = LOCAL_LR, local_momentum = LOCAL_MOMENTUM, labels_dict = LABELS_DICT, device = DEVICE,\n",
    "                attackers_ratio = atr, attack_type=ATTACK_TYPE, \n",
    "                 malicious_behavior_rate = MALICIOUS_BEHAVIOR_RATE, rule = RULE,\n",
    "                source_class = SOURCE_CLASS, target_class = TARGET_CLASS,\n",
    "               class_per_peer = CLASS_PER_PEER, samples_per_class = SAMPLES_PER_CLASS, \n",
    "               rate_unbalance = RATE_UNBALANCE, alpha = ALPHA, resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'lfighter'\n",
    "ATTACK_TYPE='label_flipping'\n",
    "MALICIOUS_BEHAVIOR_RATE = 1\n",
    "for atr in [0.4]:\n",
    "    run_exp(dataset_name = DATASET_NAME, model_name = MODEL_NAME, dd_type = DD_TYPE, num_peers = NUM_PEERS, \n",
    "            frac_peers = FRAC_PEERS, seed = SEED, test_batch_size = TEST_BATCH_SIZE,\n",
    "                criterion = CRITERION, global_rounds = GLOBAL_ROUNDS, local_epochs = LOCAL_EPOCHS, local_bs = LOCAL_BS, \n",
    "                 local_lr = LOCAL_LR, local_momentum = LOCAL_MOMENTUM, labels_dict = LABELS_DICT, device = DEVICE,\n",
    "                attackers_ratio = atr, attack_type=ATTACK_TYPE, \n",
    "                 malicious_behavior_rate = MALICIOUS_BEHAVIOR_RATE, rule = RULE,\n",
    "                source_class = SOURCE_CLASS, target_class = TARGET_CLASS,\n",
    "               class_per_peer = CLASS_PER_PEER, samples_per_class = SAMPLES_PER_CLASS, \n",
    "               rate_unbalance = RATE_UNBALANCE, alpha = ALPHA, resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
